
# Emotion Recognition App

## ğŸš€ Overview
The Emotion Recognition App is a web-based application that uses deep learning to recognize human emotions from facial expressions. Built with **Flask**, **OpenCV**, and **TensorFlow**, the app supports multiple input methods including image upload, video upload, and real-time webcam feed.

It leverages a pre-trained convolutional neural network model to classify facial emotions in various input formats.

## ğŸ¯ Features
- ğŸ“· **Image Upload**: Detect emotions in static images.
- ğŸï¸ **Video Upload**: Analyze emotions frame by frame in a video.
- ğŸ¥ **Webcam Mode**: Real-time emotion detection using your webcam.
- ğŸ”´ **Live Feed**: Continuous facial emotion recognition through a live video stream.

<details>
<summary>ğŸ“ Project Structure</summary>

```
Emotion-Detection-App/
â”‚
â”œâ”€â”€ app.py                     # Main Flask application
â”œâ”€â”€ Dockerfile                 # Docker configuration file
â”œâ”€â”€ Main.py                    # Model training script
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚
â”œâ”€â”€ app/                       # Flask app directory
â”‚   â”œâ”€â”€ static/                # Static files (CSS, JS)
â”‚   â”‚   â””â”€â”€ css/ 
â”‚   â”‚       â””â”€â”€ styles.css     # General styles
â”‚   â”‚
â”‚   â””â”€â”€ js/ 
â”‚       â””â”€â”€ script.js          # JavaScript for interactivity
â”‚   â”‚
â”‚   â””â”€â”€ templates/             # HTML templates for the app
â”‚       â”œâ”€â”€ 404.html           # Custom 404 page
â”‚       â”œâ”€â”€ index.html         # Homepage template
â”‚       â”œâ”€â”€ livefeed.html      # Live feed page
â”‚       â”œâ”€â”€ sidebar.html       # Sidebar template
â”‚       â”œâ”€â”€ upload_image.html  # Image upload page
â”‚       â”œâ”€â”€ upload_video.html  # Video upload page
â”‚       â””â”€â”€ use_webcam.html    # Webcam usage page
â”‚
â”œâ”€â”€ data/                      # Data directory (not included)
â”‚   â””â”€â”€ fer2013.csv            # FER-2013 emotion dataset
â”‚
â”œâ”€â”€ models/                    # Machine learning models and configuration (not included)
â”‚   â”œâ”€â”€ haarcascade_frontalface_default.xml  # Haar cascade for face detection
â”‚   â”œâ”€â”€ model.h5               # Pre-trained model weights
â”‚   â””â”€â”€ model.json             # Model architecture
â”‚
â””â”€â”€ uploads/                   # Temporary file storage for uploaded files

```

</details>

<details>
<summary>ğŸ› ï¸ Getting Started</summary>

### 1. Clone the Repository
```bash
git clone https://github.com/YESWANTH-S/Emotion_Recognition_App.git 
cd Emotion_Recognition_App
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Add the Model Files
Place the following files in the root project directory:
- `model.json`
- `model.h5`

> âš ï¸ These files are **not included** in the repository. You must add them manually via running the `Main.py`.

### 4. Run the Application
```bash
python app.py
```

### 5. Open in Browser
Visit: [http://127.0.0.1:5000](http://127.0.0.1:5000)

</details>

<details>
<summary>ğŸ§ª How to Use</summary>

| Feature       | URL Path           | Description                              |
|---------------|--------------------|------------------------------------------|
| Upload Image  | `/upload_image`    | Upload an image to detect emotions       |
| Upload Video  | `/upload_video`    | Analyze a video frame-by-frame           |
| Use Webcam    | `/use_webcam`      | Real-time emotion detection via webcam   |
| Live Feed     | `/livefeed`        | Continuous emotion recognition stream    |

</details>

<details>
<summary>ğŸ“¦ Dependencies</summary>

- Flask
- OpenCV
- TensorFlow
- NumPy

</details>

<details>
<summary>ğŸ³ Docker (Optional)</summary>

### Build and Run the App using Docker

```bash
docker build -t emotion-detector .
docker run -p 5000:5000 emotion-detector
```

> Make sure `model.h5` and `model.json` are in the root directory before building the image.

</details>

<details>
<summary>ğŸ¤– Model</summary>

The model is trained to detect the following emotions:
- Angry
- Disgust
- Fear
- Happy
- Neutral
- Sad
- Surprise

Note: Model training can be initiated by running the Main.py file.
</details>

---

## ğŸ“œ License
This project is licensed under the [MIT License](LICENSE).  
Contributions are welcome! If you have suggestions or improvements, feel free to open an issue or a pull request.
